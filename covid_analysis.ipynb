{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group 14 Analysis\n",
    "Milestone 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction:\n",
    "- provide some relevant background information on the topic so that someone unfamiliar with it will be prepared to understand the rest of your report.\n",
    "- clearly state the question you tried to answer with your project\n",
    "- identify and describe the dataset that was used to answer the question\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods & Results:\n",
    "- describe in written english the methods you used to perform your analysis from beginning to end that narrates the code the does the analysis.\n",
    "- your report should include code which:\n",
    "    - loads data from the original source on the web\n",
    "    - wrangles and cleans the data from itâ€™s original (downloaded) format to the format necessary for the planned classification or clustering analysis\n",
    "    - performs a summary of the data set that is relevant for exploratory data analysis related to the planned classification analysis\n",
    "    - creates a visualization of the dataset that is relevant for exploratory data analysis related to the planned classification analysis\n",
    "    - performs classification or regression analysis\n",
    "    - reates a visualization of the result of the analysis\n",
    "note: all tables and figure should have a figure/table number and a legend\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "library(tidyverse)\n",
    "library(tidymodels)\n",
    "set.seed(310)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error: 'data/US.csv' does not exist in current working directory ('/home/jovyan/work').\n",
     "output_type": "error",
     "traceback": [
      "Error: 'data/US.csv' does not exist in current working directory ('/home/jovyan/work').\nTraceback:\n",
      "1. read_csv(\"data/US.csv\")",
      "2. vroom::vroom(file, delim = \",\", col_names = col_names, col_types = col_types, \n .     col_select = {\n .         {\n .             col_select\n .         }\n .     }, id = id, .name_repair = name_repair, skip = skip, n_max = n_max, \n .     na = na, quote = quote, comment = comment, skip_empty_rows = skip_empty_rows, \n .     trim_ws = trim_ws, escape_double = TRUE, escape_backslash = FALSE, \n .     locale = locale, guess_max = guess_max, show_col_types = show_col_types, \n .     progress = progress, altrep = lazy, num_threads = num_threads)",
      "3. vroom_(file, delim = delim %||% col_types$delim, col_names = col_names, \n .     col_types = col_types, id = id, skip = skip, col_select = col_select, \n .     name_repair = .name_repair, na = na, quote = quote, trim_ws = trim_ws, \n .     escape_double = escape_double, escape_backslash = escape_backslash, \n .     comment = comment, skip_empty_rows = skip_empty_rows, locale = locale, \n .     guess_max = guess_max, n_max = n_max, altrep = vroom_altrep(altrep), \n .     num_threads = num_threads, progress = progress)",
      "4. (function (path, write = FALSE) \n . {\n .     if (is.raw(path)) {\n .         return(rawConnection(path, \"rb\"))\n .     }\n .     if (!is.character(path)) {\n .         return(path)\n .     }\n .     if (is_url(path)) {\n .         if (requireNamespace(\"curl\", quietly = TRUE)) {\n .             con <- curl::curl(path)\n .         }\n .         else {\n .             inform(\"`curl` package not installed, falling back to using `url()`\")\n .             con <- url(path)\n .         }\n .         ext <- tolower(tools::file_ext(path))\n .         return(switch(ext, zip = , bz2 = , xz = {\n .             close(con)\n .             stop(\"Reading from remote `\", ext, \"` compressed files is not supported,\\n\", \n .                 \"  download the files locally first.\", call. = FALSE)\n .         }, gz = gzcon(con), con))\n .     }\n .     path <- enc2utf8(path)\n .     p <- split_path_ext(basename_utf8(path))\n .     if (write) {\n .         path <- normalizePath_utf8(path, mustWork = FALSE)\n .     }\n .     else {\n .         path <- check_path(path)\n .     }\n .     if (is_installed(\"archive\")) {\n .         formats <- archive_formats(p$extension)\n .         extension <- p$extension\n .         while (is.null(formats) && nzchar(extension)) {\n .             extension <- split_path_ext(extension)$extension\n .             formats <- archive_formats(extension)\n .         }\n .         if (!is.null(formats)) {\n .             p$extension <- extension\n .             if (write) {\n .                 if (is.null(formats[[1]])) {\n .                   return(archive::file_write(path, filter = formats[[2]]))\n .                 }\n .                 return(archive::archive_write(path, p$path, format = formats[[1]], \n .                   filter = formats[[2]]))\n .             }\n .             if (is.null(formats[[1]])) {\n .                 return(archive::file_read(path, filter = formats[[2]]))\n .             }\n .             return(archive::archive_read(path, format = formats[[1]], \n .                 filter = formats[[2]]))\n .         }\n .     }\n .     if (!write) {\n .         compression <- detect_compression(path)\n .     }\n .     else {\n .         compression <- NA\n .     }\n .     if (is.na(compression)) {\n .         compression <- tools::file_ext(path)\n .     }\n .     if (write && compression == \"zip\") {\n .         stop(\"Can only read from, not write to, .zip\", call. = FALSE)\n .     }\n .     switch(compression, gz = gzfile(path, \"\"), bz2 = bzfile(path, \n .         \"\"), xz = xzfile(path, \"\"), zip = zipfile(path, \"\"), \n .         if (!has_trailing_newline(path)) {\n .             file(path)\n .         } else {\n .             path\n .         })\n . })(\"data/US.csv\")",
      "5. check_path(path)",
      "6. stop(\"'\", path, \"' does not exist\", if (!is_absolute_path(path)) {\n .     paste0(\" in current working directory ('\", getwd(), \"')\")\n . }, \".\", call. = FALSE)"
     ]
    }
   ],
   "source": [
    "US <- read_csv(\"data/US.csv\")\n",
    "head(US)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "aggregated_clean <- aggregated |>\n",
    "select(location_key, data, country)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion:\n",
    "- summarize what you found\n",
    "- discuss whether this is what you expected to find?\n",
    "- discuss what impact could such findings have?\n",
    "- discuss what future questions could this lead to?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References:\n",
    "at least 4 citations relevant to the project (format is your choose, just be consistent across the references)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
